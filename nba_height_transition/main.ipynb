{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nba_apiからデータの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nba_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching season: 1980-81\n",
      "Fetching season: 1981-82\n",
      "Fetching season: 1982-83\n",
      "Fetching season: 1983-84\n",
      "Fetching season: 1984-85\n",
      "Fetching season: 1985-86\n",
      "Fetching season: 1986-87\n",
      "Fetching season: 1987-88\n",
      "Fetching season: 1988-89\n",
      "Fetching season: 1989-90\n",
      "Fetching season: 1990-91\n",
      "Fetching season: 1991-92\n",
      "Fetching season: 1992-93\n",
      "Fetching season: 1993-94\n",
      "Fetching season: 1994-95\n",
      "Fetching season: 1995-96\n",
      "Fetching season: 1996-97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-2>:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching season: 1997-98\n",
      "Fetching season: 1998-99\n",
      "Fetching season: 1999-00\n",
      "Fetching season: 2000-01\n",
      "Fetching season: 2001-02\n",
      "Fetching season: 2002-03\n",
      "Fetching season: 2003-04\n",
      "Fetching season: 2004-05\n",
      "Fetching season: 2005-06\n",
      "Fetching season: 2006-07\n",
      "Fetching season: 2007-08\n",
      "Fetching season: 2008-09\n",
      "Fetching season: 2009-10\n",
      "Fetching season: 2010-11\n",
      "Fetching season: 2011-12\n",
      "Fetching season: 2012-13\n",
      "Fetching season: 2013-14\n",
      "Fetching season: 2014-15\n",
      "Fetching season: 2015-16\n",
      "Fetching season: 2016-17\n",
      "Fetching season: 2017-18\n",
      "Fetching season: 2018-19\n",
      "Fetching season: 2019-20\n",
      "Fetching season: 2020-21\n",
      "Fetching season: 2021-22\n",
      "Fetching season: 2022-23\n",
      "Fetching season: 2023-24\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import leaguedashplayerstats\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_season_stats(season):\n",
    "    # \"1980-81\" の形式に整形\n",
    "    season_str = f\"{season}-{str(season+1)[-2:]}\"\n",
    "    print(f\"Fetching season: {season_str}\")\n",
    "\n",
    "    try:\n",
    "        stats = leaguedashplayerstats.LeagueDashPlayerStats(\n",
    "            season=season_str,\n",
    "            season_type_all_star='Regular Season',\n",
    "            per_mode_detailed='PerGame'\n",
    "        ).get_data_frames()[0]\n",
    "        stats['SEASON'] = season_str\n",
    "        return stats\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {season_str}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# 10年区切りでデータ取得\n",
    "all_data = pd.DataFrame()\n",
    "for start_year in range(1980, 2024):  # 1980-81 ～ 2023-24\n",
    "    df = fetch_season_stats(start_year)\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "    time.sleep(1)  # API制限対策\n",
    "\n",
    "# 必要なカラムだけ抽出\n",
    "df_use = all_data[['SEASON', 'PLAYER_NAME', 'PLAYER_ID', 'TEAM_ABBREVIATION', 'GP', 'MIN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shoku\\anaconda3\\envs\\clean-base\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\shoku\\anaconda3\\envs\\clean-base\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:37<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from nba_api.stats.endpoints import commonplayerinfo\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# df_use の先頭50人のPLAYER_IDを取得\n",
    "test_ids = df_use['PLAYER_ID'].unique()[:50]\n",
    "\n",
    "# キャッシュファイルのパス\n",
    "CACHE_PATH = \"player_info_cache.json\"\n",
    "\n",
    "# 既に取得済みならそれをロード\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    with open(CACHE_PATH, \"r\") as f:\n",
    "        player_info_dict = json.load(f)\n",
    "else:\n",
    "    player_info_dict = {}\n",
    "\n",
    "# データ取得関数\n",
    "def get_player_height_and_position(player_id):\n",
    "    try:\n",
    "        info = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "        height = info['HEIGHT'].values[0]  # 例: \"6-5\"\n",
    "        position = info['POSITION'].values[0]  # 例: \"G-F\"\n",
    "        return height, position\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# 選手情報取得ループ（キャッシュ付き）\n",
    "for pid in tqdm(test_ids):\n",
    "    pid_str = str(pid)\n",
    "    if pid_str in player_info_dict:\n",
    "        continue\n",
    "    height, pos = get_player_height_and_position(pid)\n",
    "    player_info_dict[pid_str] = {'HEIGHT': height, 'POSITION': pos}\n",
    "    time.sleep(0.5)\n",
    "    with open(CACHE_PATH, \"w\") as f:\n",
    "        json.dump(player_info_dict, f)\n",
    "\n",
    "# 結果をDataFrameに変換\n",
    "info_df = pd.DataFrame.from_dict(player_info_dict, orient='index').reset_index().rename(columns={'index': 'PLAYER_ID'})\n",
    "info_df['PLAYER_ID'] = info_df['PLAYER_ID'].astype(int)  # マージのため型揃える\n",
    "df_test = pd.merge(df_use, info_df, on='PLAYER_ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 649/2652 [48:40<15:04:17, 27.09s/it]"
     ]
    }
   ],
   "source": [
    "# # フル\n",
    "# from nba_api.stats.endpoints import commonplayerinfo\n",
    "\n",
    "# def get_player_height_and_position(player_id):\n",
    "#     try:\n",
    "#         info = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "#         height = info['HEIGHT'].values[0]  # 例: \"6-5\"\n",
    "#         position = info['POSITION'].values[0]  # 例: \"G-F\"\n",
    "#         return height, position\n",
    "#     except:\n",
    "#         return None, None\n",
    "\n",
    "# # 一意のPLAYER_IDでループ\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# player_info_dict = {}\n",
    "# for pid in tqdm(df_use['PLAYER_ID'].unique()):\n",
    "#     height, pos = get_player_height_and_position(pid)\n",
    "#     player_info_dict[pid] = {'HEIGHT': height, 'POSITION': pos}\n",
    "#     time.sleep(0.5)  # API制限回避のためのウェイト\n",
    "\n",
    "# # DataFrame化してマージ\n",
    "# info_df = pd.DataFrame.from_dict(player_info_dict, orient='index').reset_index().rename(columns={'index': 'PLAYER_ID'})\n",
    "# df_final = pd.merge(df_use, info_df, on='PLAYER_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 587/2652 [20:56<15:00:01, 26.15s/it]"
     ]
    }
   ],
   "source": [
    "# フル（キャッシュ付き）\n",
    "\n",
    "from nba_api.stats.endpoints import commonplayerinfo\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# キャッシュファイルの保存先\n",
    "CACHE_PATH = \"player_info_cache.json\"\n",
    "\n",
    "# データ準備（前提：df_useが全期間のプレイヤーデータ）\n",
    "player_ids = df_use['PLAYER_ID'].unique()\n",
    "\n",
    "# キャッシュがあればロード\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    with open(CACHE_PATH, \"r\") as f:\n",
    "        player_info_dict = json.load(f)\n",
    "else:\n",
    "    player_info_dict = {}\n",
    "\n",
    "# プレイヤー情報取得関数\n",
    "def get_player_height_and_position(player_id):\n",
    "    try:\n",
    "        info = commonplayerinfo.CommonPlayerInfo(player_id=player_id).get_data_frames()[0]\n",
    "        height = info['HEIGHT'].values[0]\n",
    "        position = info['POSITION'].values[0]\n",
    "        return height, position\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "# 本番ループ（未取得のみ）\n",
    "for pid in tqdm(player_ids):\n",
    "    pid_str = str(pid)\n",
    "    if pid_str in player_info_dict:\n",
    "        continue  # キャッシュ済みはスキップ\n",
    "    height, pos = get_player_height_and_position(pid)\n",
    "    player_info_dict[pid_str] = {'HEIGHT': height, 'POSITION': pos}\n",
    "    time.sleep(0.6)  # API対策でゆっくり\n",
    "    with open(CACHE_PATH, \"w\") as f:\n",
    "        json.dump(player_info_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict → DataFrame化してマージ\n",
    "info_df = pd.DataFrame.from_dict(player_info_dict, orient='index').reset_index().rename(columns={'index': 'PLAYER_ID'})\n",
    "info_df['PLAYER_ID'] = info_df['PLAYER_ID'].astype(int)  # マージのため型合わせ\n",
    "df_merged = pd.merge(df_use, info_df, on='PLAYER_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inch->cm\n",
    "def height_to_cm(height_str):\n",
    "    try:\n",
    "        feet, inches = map(int, height_str.split('-'))\n",
    "        return round((feet * 12 + inches) * 2.54, 1)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def simplify_position(pos_str):\n",
    "    try:\n",
    "        if 'Guard' in pos_str:\n",
    "            return 'PG' if 'Point' in pos_str else 'G'\n",
    "        elif 'Forward' in pos_str:\n",
    "            return 'F'\n",
    "        elif 'Center' in pos_str:\n",
    "            return 'C'\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_merged['HEIGHT_CM'] = df_merged['HEIGHT'].apply(height_to_cm)\n",
    "df_merged['POSITION_SIMPLE'] = df_merged['POSITION'].apply(simplify_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lv.1 / Lv.2 / Lv.1&2 フィルター用のフラグ追加\n",
    "df_merged['Lv1'] = df_merged['GP'] >= 41\n",
    "df_merged['Lv2'] = df_merged['MIN'] >= 20\n",
    "df_merged['Lv1_and_Lv2'] = df_merged['Lv1'] & df_merged['Lv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm\n",
    "df_merged[['SEASON', 'PLAYER_NAME', 'HEIGHT', 'HEIGHT_CM', 'POSITION', 'POSITION_SIMPLE', 'Lv1', 'Lv2', 'Lv1_and_Lv2']].head(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
